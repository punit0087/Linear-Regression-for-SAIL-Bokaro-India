{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining And Machine Learning For IOT Applications In Industry at SAIL, Bokaro, India - Linear Regression\n",
    "\n",
    "The contents of this notebook are taken (and modified) from the COMP90051 course (workshop) at the University of Melbourne, Australia.\n",
    "\n",
    "\n",
    "\n",
    "## Part A: Simple Linear regression\n",
    "\n",
    "***\n",
    "\n",
    "The aim of this part of the workshop is to get you coding linear regression models in Python, relying on the `numpy` library. We will do it in three ways: One based on approximate iterative updates (coordinate descenet), second based on linear algebra (Normal equations), and third based on `sklearn`. The correctness of the first two implementations (from scratch) will be verified by comparing their ouputs to the output of `sklearn`.\n",
    "\n",
    "\n",
    "Firstly, we will import the relevant libraries (`numpy`, `matplotlib`, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check what a command does simply type `object?`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Review\n",
    "In the lecture, we saw that a linear model can be expressed as:\n",
    "$$y = w_0 + \\sum_{j = 1}^{d} w_j x_j = \\mathbf{w} \\cdot \\mathbf{x} $$\n",
    "where \n",
    "\n",
    "* $y$ is the *response or target variable*;\n",
    "* $\\mathbf{x} = [x_1, \\ldots, x_d]$ is a vector of *features* (we define $x_0 = 1$); and\n",
    "* $\\mathbf{w} = [w_0, \\ldots, w_d]$ are the *weights*.\n",
    "\n",
    "To fit the model, we *minimise* the sum of squared residuals (errors), SSR:\n",
    "\n",
    "$$SSR(\\mathbf{w}) = \\sum_{i=1}^{n}(y^{(i)} - \\mathbf{w} \\cdot \\mathbf{x}^{(i)})^2$$\n",
    "\n",
    "**Note:** For simplicity, we'll consider the case $d = 1$ (i.e. only one feature excluding the intercept)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data set\n",
    "We'll be working with some data from the Olympicsâ€”the gold medal race times for marathon winners from 1896 to 2012. The code block below reads the data into a numpy array of floats, and prints the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file with variables YEAR,TIME\n",
    "csv = \"\"\"1896,4.47083333333333\n",
    "1900,4.46472925981123\n",
    "1904,5.22208333333333\n",
    "1908,4.1546786744085\n",
    "1912,3.90331674958541\n",
    "1920,3.5695126705653\n",
    "1924,3.8245447722874\n",
    "1928,3.62483706600308\n",
    "1932,3.59284275388079\n",
    "1936,3.53880791562981\n",
    "1948,3.6701030927835\n",
    "1952,3.39029110874116\n",
    "1956,3.43642611683849\n",
    "1960,3.2058300746534\n",
    "1964,3.13275664573212\n",
    "1968,3.32819844373346\n",
    "1972,3.13583757949204\n",
    "1976,3.07895880238575\n",
    "1980,3.10581822490816\n",
    "1984,3.06552909112454\n",
    "1988,3.09357348817\n",
    "1992,3.16111703598373\n",
    "1996,3.14255243512264\n",
    "2000,3.08527866650867\n",
    "2004,3.1026582928467\n",
    "2008,2.99877552632618\n",
    "2012,3.03392977050993\"\"\"\n",
    "\n",
    "# Read into a numpy array (as floats)\n",
    "olympics = np.genfromtxt(io.BytesIO(csv.encode()), delimiter=\",\")\n",
    "print(olympics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the data into numpy array. We'll take the race time as the *target variable* $y$ and the year of the race as the only *feature* $x = x_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = olympics[:, 0:1]\n",
    "y = olympics[:, 1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can make a plot of $y$ vs $x$ with the following commands. Can a linear model be a decent fit for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'rx')\n",
    "plt.ylabel(\"y (Race time)\")\n",
    "plt.xlabel(\"x (Year of race)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Approximate Iterative solution (coordinate descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding out the sum of square residuals for this simple case (where $\\mathbf{w}=[w_0, w_1]$) we have:\n",
    "$$SSR(w_0, w_1) = \\sum_{i=1}^{n}(y_i - w_0 - w_1 x_i)^2$$\n",
    "Let's start with an initial guess for the slope $w_1$ (which is clearly negative from the plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = -0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then using the maximum likelihood update, we get the following estimate for the intercept $w_0$:\n",
    "$$w_0 = \\frac{\\sum_{i=1}^{n}(y_i-w_1 x_i)}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = ... # over to you\n",
    "print(w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can update $w_1$ based on this new estimate of $w_0$:\n",
    "$$w_1 = \\frac{\\sum_{i=1}^{n} (y_i - w_0) \\times x_i}{\\sum_{i=1}^{n} x_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = ... # over to you\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the quality of fit for these values for the weights $w_0$ and $w_1$. First, we create a vector of \"test\" values `x_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.arange(1890, 2020)[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, use this vector to compute some test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = ... # over to you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the test predictions with a blue line on the same plot as the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(x_test, y_test, x, y): \n",
    "    plt.plot(x_test, y_test, 'b-')\n",
    "    plt.plot(x, y, 'rx')\n",
    "    plt.ylabel(\"y (Race time)\")\n",
    "    plt.xlabel(\"x (Year of race)\")\n",
    "    plt.show()\n",
    "\n",
    "plot_fit(x_test, y_test, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the quality of the fit by evaluating the average sum of squares error of the prediction over the training samples, $SSR(w_0,w_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SSR(x, y, w0, w1): \n",
    "    return ... # over to you\n",
    "\n",
    "print(compute_SSR(x, y, w0, w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's obvious from the plot that the fit isn't very good. \n",
    "We must repeat the alternating parameter updates many times before the algorithm converges to the optimal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(10000):\n",
    "    w1 = ... # paste from above\n",
    "    w0 = ... # paste from above\n",
    "    if i % 500 == 0:\n",
    "        print(\"Iteration #{}: SSR = {}\".format(i, compute_SSR(x, y, w0, w1)))\n",
    "print(\"Final estimates: w0 = {}; w1 = {}\".format(w0, w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try plotting the result again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = ... # paste from above\n",
    "plot_fit(x_test, y_test, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Linear algebra solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lecture, we saw that it's possible to solve for the optimal weights $\\mathbf{w}^\\star$ analytically. The solution is\n",
    "$$\\mathbf{w}^* = \\left[\\mathbf{X}^\\top \\mathbf{X}\\right]^{-1} \\mathbf{X}^\\top \\mathbf{y}$$\n",
    "where\n",
    "$$\\mathbf{X} = \\begin{pmatrix} \n",
    "        1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \n",
    "    \\end{pmatrix} \n",
    "  \\quad \\text{and} \\quad \n",
    "  \\mathbf{y} = \\begin{pmatrix} \n",
    "          y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n",
    "      \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "We construct $\\mathbf{X}$ in the code block below, remembering to include the $x_0 = 1$ column for the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((np.ones_like(x), x))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we can express $\\mathbf{w}^\\star$ explicitly in terms of the matrix inverse $(\\mathbf{X}^\\top \\mathbf{X})^{-1}$, this isn't an efficient way to compute $\\mathbf{w}$ numerically. It is better instead to solve the following system of linear equations:\n",
    "$$\\mathbf{X}^\\top\\mathbf{X} \\mathbf{w}^\\star = \\mathbf{X}^\\top\\mathbf{y}$$\n",
    "\n",
    "This can be done in numpy using the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ... # back to you\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting this solution, as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, w1 = w\n",
    "y_test = ... # paste from above \n",
    "plot_fit(x_test,y_test, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should verify that the sum of squared residuals $SSR(w_0, w_1)$, match or beats the earlier iterative result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_SSR(x, y, w0, w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5. Solving using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a good understanding of what's going on under the hood, you can use the functionality in `sklearn` to solve linear regression problems you encounter in the future. Using the `LinearRegression` module, fitting a linear regression model becomes a one-liner as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LinearRegression` module provides access to the bias weight $w_0$ under the `intercept_` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the non-bias weights under the `coef_` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = lr.intercept_ + lr.coef_ * x_test\n",
    "plot_fit(x_test,y_test, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_SSR(x, y, w0, w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should check that these results match the solution you obtained previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Model Complexity and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part will review overfitting, model selection and regularisation. Note that the lessons here apply equally to classification, however it's more convenient to visualise regression models, and they are also much simpler to fit to data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** We will consider regression models of varying complexity, from a simple linear model to polynomial models of varying order.\n",
    "Q1: Based on the Olympic marathon data, what order model do you think is going to perform the best? (*Hint*: In making your decision, think about the *interpolation* predictions for years between Olympics (e.g., 2015), and *extrapolations* into the future, e.g., 2016, 2020, 2040, etc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will consider a more complex polynomial function. Where before we had instances of the form,\n",
    "$$\\phi(\\mathbf{x}) = [ 1~ x ]$$ \n",
    "now we will be using e.g., \n",
    "$$\\phi(\\mathbf{x}) = [ 1 ~x~ x^2~ x^3~ x^4]$$ \n",
    "for a quartic model. We will consider a range of polynomial models of different orders. \n",
    "\n",
    "To implement this we will use *basis functions* which provide a neat way of representing our data instances such that we can still use all the linear models to acheive learn a non-linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = x.shape[0]\n",
    "num_pred_data = 100 # how many points to use for plotting predictions\n",
    "x_pred = np.linspace(1890, 2016, num_pred_data)[:, None] # input locations for predictions\n",
    "order = 4 # The polynomial order to use.\n",
    "print ('Num of training samples: ',num_data)\n",
    "print('Num of testing samples: ',num_pred_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the *basis* matrices $\\Phi$ to represent the training data, where each column is raising the input year $X$ to various powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi = np.zeros((num_data, order+1))\n",
    "Phi_pred = np.zeros((num_pred_data, order+1))\n",
    "for i in range(0, order+1):\n",
    "    Phi[:, i:i+1] = x**i\n",
    "    Phi_pred[:, i:i+1] = x_pred**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model\n",
    "\n",
    "Now we can solve for the regression weights and make predictions both for the training data points, and the test data points. That involves solving the linear system given by\n",
    "\n",
    "$$\\Phi' \\Phi \\mathbf{w} = \\Phi' \\mathbf{y}$$\n",
    "\n",
    "with respect to $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve the linear system\n",
    "w = ... # over to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use resulting vector to make predictions at the training points and test points\n",
    "f = ... # over to you\n",
    "f_pred = ... # over to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the sum of squares error\n",
    "SSR =  ... # paste from above    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have the fit and the error, so let's plot the fit and the error.\n",
    "print(\"The error is: %2.4f\"%SSR)\n",
    "plt.plot(x_pred, f_pred)\n",
    "plt.plot(x, y, 'rx')\n",
    "ax = plt.gca()\n",
    "ax.set_title('Predictions for Order 5')\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('pace (min/km)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the loop structure below to compute the error for different model orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the time model to allow python to pause.\n",
    "# import the IPython display module to clear the output.\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "error_list = []\n",
    "max_order = 6\n",
    "#fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "fig1=plt.figure(figsize=(15,2*max_order))\n",
    "index=1\n",
    "\n",
    "for order in range(0, max_order+1):\n",
    "    # 1. build the basis set\n",
    "    Phi = np.zeros((num_data, order+1))\n",
    "    Phi_pred = np.zeros((num_pred_data, order+1))\n",
    "    for i in range(0, order+1):\n",
    "        Phi[:, i:i+1] = .. # paste from above\n",
    "        Phi_pred[:, i:i+1] = .. # paste from above\n",
    "    # 2. solve the linear system\n",
    "    w = ... # paste from above\n",
    "\n",
    "    # 3. make predictions at training and test points\n",
    "    f = ... # paste from above\n",
    "    f_pred = ... # paste from above\n",
    "    \n",
    "    # 4. compute the error and append it to a list.\n",
    "    SSR = ... # paste from above    \n",
    "    error_list.append(SSR)\n",
    "    \n",
    "    # 5. plot the predictions\n",
    "    fig1.add_subplot(max_order+1,2,index)\n",
    "    plt.plot(x_pred, f_pred)\n",
    "    plt.plot(x, y, 'rx')\n",
    "    plt.ylim((2.5, 5.5))\n",
    "    if (order ==0):\n",
    "        plt.title('Predictions for Order ' + str(order) + ' model.')\n",
    "    \n",
    "    \n",
    "    fig1.add_subplot(max_order+1,2,index+1)\n",
    "    plt.plot(np.arange(0, order+1), np.asarray(error_list))\n",
    "    plt.xlim((0, order+1))\n",
    "    plt.ylim((0, np.max(error_list)))\n",
    "    if (order ==0):\n",
    "        plt.title('Training Error')\n",
    "    index= index+2\n",
    "\n",
    "plt.show()\n",
    "#display(fig)\n",
    "print('Training error list: ',error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** Looks like a great fit. Does that mean we can stop here, our job is done? You might want to try an order 20 or higher model, also to see if the fits continue to improve with higher order models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** What do you think might happen if we try to fit an order 100 model to this data? Is this even a reasonable thing to try?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold Out Validation\n",
    "\n",
    "The error we computed above is the training error. It doesn't assess the model's generalization ability, it only assesses how well it's performing on the given training data. \n",
    "\n",
    "\n",
    "In hold out validation, we keep back some of the training data for assessing generalization performance. In the case of time series prediction, it often makes sense to hold out the last few data points, in particular, when we are interested in *extrapolation*, i.e. predicting into the future given the past. To perform hold out validation, we first remove the hold out set. If we were interested in interpolation, we would hold out some random points. Here, because we are interested in extrapolation, we will hold out all points since 1980. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training set\n",
    "x_train = x\n",
    "y_train = y\n",
    "indices_hold_out = np.nonzero(x>1980)\n",
    "\n",
    "\n",
    "x_train = np.delete(x, indices_hold_out)[:,None]\n",
    "y_train = np.delete(y, indices_hold_out)[:,None]\n",
    "\n",
    "# Create a hold out set\n",
    "x_hold_out = x[indices_hold_out][:,None]\n",
    "y_hold_out = y[indices_hold_out][:,None]\n",
    "\n",
    "\n",
    "print ('Whole dataset size', x.shape)\n",
    "print('Train split size: ', x_train.shape)\n",
    "print('Test split size: ', x_hold_out.shape)\n",
    "\n",
    "# Now use the training set and hold out set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have the training and hold out data, you should be able to use the code above to evaluate the model on the hold out data. Do this in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "max_order = 6\n",
    "#fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "fig1=plt.figure(figsize=(12,max_order*2))\n",
    "index = 1\n",
    "for order in range(0, max_order+1):\n",
    "    # 1. build the basis set using x_train, x_hold_out\n",
    "    Phi = np.zeros((x_train.shape[0], order+1))\n",
    "    Phi_pred = np.zeros((num_pred_data, order+1))\n",
    "    Phi_hold_out = np.zeros((x_hold_out.shape[0], order+1))\n",
    "    for i in range(0, order+1):\n",
    "        Phi[:, i:i+1] = ... # back to you\n",
    "        Phi_hold_out[:, i:i+1] = ... # back to you\n",
    "        Phi_pred[:, i:i+1] = ... # back to you\n",
    "        \n",
    "    # 2. solve the linear system\n",
    "    w = ... # back to you\n",
    "\n",
    "    # 3. make predictions at training and test points\n",
    "    f = ... # back to you\n",
    "    f_hold_out = ... # back to you\n",
    "    f_pred = ... # back to you\n",
    "    \n",
    "    # 4. compute the error and append it to a list.\n",
    "    error = ... # back to you   \n",
    "    error_list.append(error)\n",
    "    \n",
    "    # 5. plot the predictions\n",
    "    fig1.add_subplot(max_order+1,2,index)\n",
    "    plt.plot(x_pred, f_pred)\n",
    "    plt.plot(x, y, 'rx')\n",
    "    plt.ylim((2.5, 5.5))\n",
    "    if (order ==0):\n",
    "        plt.title('Predictions for Order ' + str(order) + ' model.')\n",
    "    \n",
    "    \n",
    "    fig1.add_subplot(max_order+1,2,index+1)\n",
    "    plt.plot(np.arange(0, order+1), np.asarray(error_list))\n",
    "    plt.xlim((0, order+1))\n",
    "    plt.ylim((0, np.max(error_list)))\n",
    "    if (order ==0):\n",
    "        plt.title('Training Error')\n",
    "    index= index+2\n",
    "\n",
    "plt.show()\n",
    "#display(fig)\n",
    "print('Holdout error list: ', error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** What is going on here? Does this match your earlier findings, or your intuition about which model order was most appropriate? Why isn't held-out error behaving the same as training error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularising the model, using ridge regression\n",
    "\n",
    "A nice way to limit model complexity is *regularisation* where model parameters are penalised from moving to silly values. Here we consider silly as high magnitude, which means the model is getting overly confident. Can you explain why this might be a problem? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use a 6th order model, which you might consider much too powerful for this simple problem. As a first step, we'll preprocess the features to ensure they are all operating in a similar range. E.g., $2000^6 >> 2000^1$, which means the weights for the 6th order features will take on radically different values to the 1st order features. To correct for this, and allow regularisation with a single constant, we'll normalize (z-score) the columns of training Phi to have zero mean and unit standard deviation. This same transformation is also applied to the testing basis matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 6\n",
    "Phi = np.zeros((x_train.shape[0], order+1))\n",
    "Phi_pred = np.zeros((num_pred_data, order+1))\n",
    "Phi_hold_out = np.zeros((x_hold_out.shape[0], order+1))\n",
    "for i in range(0, order+1):\n",
    "    Phi[:, i:i+1] = x_train**i\n",
    "    if i > 0:\n",
    "        mean = Phi[:, i:i+1].mean()\n",
    "        std = Phi[:, i:i+1].std()\n",
    "        print(i,mean,std)\n",
    "    else: # as the first column is constant, need to avoid divide by zero \n",
    "        mean = 0\n",
    "        std = 1\n",
    "    \n",
    "    Phi[:, i:i+1] = (Phi[:, i:i+1] - mean) / std\n",
    "    Phi_hold_out[:, i:i+1] = (x_hold_out**i - mean) / std\n",
    "    Phi_pred[:, i:i+1] = (x_pred**i - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we'll perform training, trying out different values of the regularisation coefficient, lambda.\n",
    "error_list = []\n",
    "train_error_list = []\n",
    "lambdas = [1e-10, 1e-6, 1e-4, 1e-2, 1, 100] \n",
    "order = 6\n",
    "#fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "fig1=plt.figure(figsize=(16,order*4))\n",
    "index =1\n",
    "for l, lamba in enumerate(lambdas):\n",
    "    # 1. build the basis set using x_train, x_hold_out\n",
    "    # done above\n",
    "        \n",
    "    # 2. solve the linear system\n",
    "    w = np.linalg.solve(np.dot(Phi.T, Phi) + lamba * np.eye(order+1), np.dot(Phi.T, y_train))\n",
    "\n",
    "    # 3. make predictions at training and test points\n",
    "    f = np.dot(Phi, w)\n",
    "    f_hold_out = np.dot(Phi_hold_out, w)\n",
    "    f_pred = np.dot(Phi_pred, w)\n",
    "    \n",
    "    # 4. compute the error and append it to a list.\n",
    "    error = ((y_hold_out-f_hold_out)**2).sum()    \n",
    "    error_list.append(error)\n",
    "    train_error = ((y_train-f)**2).sum()    \n",
    "    train_error_list.append(train_error)\n",
    "    \n",
    "    # 5. plot the predictions\n",
    "    fig1.add_subplot(len(lambdas)+1,3,index)\n",
    "    plt.plot(x_pred, f_pred)\n",
    "    plt.plot(x, y, 'rx')\n",
    "    plt.ylim(2.5, 5.5)\n",
    "    if (l==0):\n",
    "        plt.title('Pred. for Lambda ' + str(lamba))\n",
    "    else: \n",
    "        plt.title(str(lamba))\n",
    "        \n",
    "    fig1.add_subplot(len(lambdas)+1,3,index+1)\n",
    "    plt.plot(lambdas[:l+1], np.asarray(error_list))\n",
    "    plt.xlim((min(lambdas), max(lambdas)))\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0, 12)\n",
    "    if (l==0):\n",
    "        plt.title('Held-out Error (validation/testing)')\n",
    "    \n",
    "    \n",
    "    fig1.add_subplot(len(lambdas)+1,3,index+2)\n",
    "    plt.plot(lambdas[:l+1], np.asarray(train_error_list))\n",
    "    plt.xlim(min(lambdas), max(lambdas))\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0, 12)\n",
    "    if (l == 0):\n",
    "        plt.title('Training Error')\n",
    "    index= index+3\n",
    "\n",
    "plt.show()\n",
    "#display(fig)\n",
    "print('Holdout error list: ',error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** What setting gives the best heldout performance? How does this relate to the training error, and can you describe whether you see evidence of overfitting or underfitting?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
